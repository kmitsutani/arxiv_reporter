# process_papers_and_email.py
import os
import smtplib
import time
from datetime import datetime
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

import feedparser
import pandas as pd
import requests

KEYWORDS = [
    "axiomatic quantum field theory", "algebraic quantum field theory", "AQFT", "Ryu-Takayanagi",
    "measurement-induced", "resource theory", "resource theoretic",
    "Haag", "LSZ", "conformal bootstrap", "duality",
    "non-perturbative", "Yang Mills", "Renormalization Group", "MERA",
]
RSS_FEEDS = [
    "https://rss.arxiv.org/rss/hep-th", "https://rss.arxiv.org/rss/math-ph",
    "https://rss.arxiv.org/rss/quant-ph",
]
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«reportsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’è¨­å®š
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
REPORTS_DIR = os.path.join(SCRIPT_DIR, "reports")


def fetch_and_filter_papers():
    print("Fetching papers from RSS feeds...")
    unique_papers = {}
    for url in RSS_FEEDS:
        print(f"  - Fetching {url}")
        feed = feedparser.parse(url)
        for entry in feed.entries:
            if entry.id not in unique_papers:
                unique_papers[entry.id] = entry
        time.sleep(1)
    print(f"\nFound {len(unique_papers)} unique new papers. Filtering by keywords...")
    filtered_papers = []
    for entry in unique_papers.values():
        title_lower = entry.title.lower()
        summary_lower = entry.summary.lower()
        is_hit = [keyword.lower() in title_lower or keyword.lower()
                  in summary_lower for keyword in KEYWORDS]

        if sum(is_hit) > 0:
            true_idx = [i for i, val in enumerate(is_hit) if val]
            hit_keywords = [KEYWORDS[i] for i in true_idx]

            parsed_authors = []
            if hasattr(entry, 'authors') and entry.authors:
                author_string = entry.authors[0].get('name', '')
                author_names = [name.strip() for name in author_string.split(',')]
                for name in author_names:
                    parsed_authors.append({'name': name})
            filtered_papers.append({
                "id": entry.id, "published": entry.published, "title": entry.title,
                "summary": entry.summary, "url": entry.link, "authors": parsed_authors,
                "keywords": hit_keywords,
            })
    print(f"  -> Found {len(filtered_papers)} relevant papers.")
    return filtered_papers


def evaluate_authors_via_semantic_scholar(authors):
    evaluated_authors = []
    if not authors: return evaluated_authors
    for author in authors:
        author_name = author.get("name")
        if not author_name: continue
        print(f"    - Evaluating author: {author_name}")
        try:
            api_url = f"https://api.semanticscholar.org/graph/v1/author/search?query={requests.utils.quote(author_name)}&fields=hIndex,citationCount,paperCount,url"
            response = requests.get(api_url, timeout=10)
            response.raise_for_status()
            if response.json().get("data"):
                author_data = response.json()["data"][0]
                evaluation = {"name": author_name, "hIndex": author_data.get("hIndex", 0),
                              "citations": author_data.get("citationCount", 0),
                              "papers": author_data.get("paperCount", 0),
                              "semantic_scholar_url": author_data.get("url", "#")}
                evaluated_authors.append(evaluation)
        except requests.exceptions.RequestException as e:
            print(f"      -> API Error for {author_name}: {e}")
        time.sleep(1)
    return evaluated_authors


def get_score_label_and_class(score):
    # (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
    if score >= 100: return "ä¸–ç•Œçš„æ¨©å¨", "score-s-plus"
    elif score >= 50: return "ãƒˆãƒƒãƒ—ç ”ç©¶è€…", "score-s"
    elif score >= 20: return "ä¸­æ ¸ç ”ç©¶è€…", "score-a"
    elif score >= 10: return "æ³¨ç›®ç ”ç©¶è€…", "score-b"
    else: return "è‹¥æ‰‹ç ”ç©¶è€…", "score-c"


def get_score_emoji(score):
    # (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—)
    if score >= 100: return "ğŸ†"
    elif score >= 50: return "ğŸ…"
    elif score >= 20: return "ğŸŸ¢"
    elif score >= 10: return "ğŸ”µ"
    else: return "âšª"


def extract_arxiv_id(arxiv_url):
    """arXiv URLã‹ã‚‰arXiv IDï¼ˆä¾‹ï¼š2409.12345ï¼‰ã‚’æŠ½å‡ºã™ã‚‹"""
    import re
    # arXiv URLã‹ã‚‰IDã‚’æŠ½å‡ºï¼ˆä¾‹ï¼šhttp://arxiv.org/abs/2409.12345 â†’ 2409.12345ï¼‰
    match = re.search(r'arxiv\.org/abs/(\d{4}\.\d{4,5}(?:v\d+)?)', arxiv_url)
    if match:
        return match.group(1)
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šURLã®æœ€å¾Œã®éƒ¨åˆ†ã‚’ä½¿ç”¨
    return arxiv_url.split('/')[-1]


def generate_markdown_report(processed_papers):
    """GitHub Flavored Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    today_str = datetime.now().strftime("%Y-%m-%d")
    md_content = f"# arXiv è«–æ–‡ãƒ¬ãƒãƒ¼ãƒˆ ({today_str})\n\n"

    if not processed_papers:
        md_content += "_æœ¬æ—¥ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åˆè‡´ã™ã‚‹æ–°ç€è«–æ–‡ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚_\n"
    else:
        processed_papers.sort(key=lambda p: p.get("preprint_score", 0), reverse=True)
        for i, paper in enumerate(processed_papers):
            score = paper.get("preprint_score", 0)
            score_label, _ = get_score_label_and_class(score)
            score_emoji = get_score_emoji(score)
            paper_id = extract_arxiv_id(paper['id'])
            published_date = pd.to_datetime(paper['published']).strftime('%Y-%m-%d %H:%M')

            # è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚¹ã‚³ã‚¢
            md_content += f"## {score_emoji} [{paper['title']}]({paper['url']})\n\n"
            md_content += f"**Score: {score} ({score_label})**\n\n"

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            md_content += f"**Keywords:** {' â€¢ '.join(paper['keywords'])}\n\n"

            # å…¬é–‹æ—¥
            md_content += f"**å…¬é–‹æ—¥:** {published_date}\n\n"

            # è‘—è€…æƒ…å ±
            if paper.get("authors_evaluation"):
                md_content += "### è‘—è€…æƒ…å ± (Semantic Scholar)\n\n"
                md_content += "| è‘—è€… | h-index | è¢«å¼•ç”¨æ•° | è«–æ–‡æ•° |\n"
                md_content += "|------|---------|----------|--------|\n"
                for author_eval in paper["authors_evaluation"]:
                    name = author_eval['name']
                    url = author_eval['semantic_scholar_url']
                    h_index = author_eval['hIndex']
                    citations = f"{author_eval['citations']:,}"
                    papers = author_eval['papers']
                    md_content += f"| [{name}]({url}) | {h_index} | {citations} | {papers} |\n"
                md_content += "\n"

            # ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ
            md_content += "### ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ (åŸæ–‡)\n\n"
            md_content += f"> {paper.get('summary', 'N/A')}\n\n"
            md_content += "---\n\n"

    return md_content



def get_github_markdown_url():
    """git remoteã®æƒ…å ±ã‹ã‚‰GitHubä¸Šã®Markdownãƒ•ã‚¡ã‚¤ãƒ«URLã‚’ç”Ÿæˆã™ã‚‹"""
    import subprocess
    import re

    try:
        # git remoteã®URLã‚’å–å¾—
        result = subprocess.run(
            ["git", "remote", "get-url", "origin"],
            cwd=SCRIPT_DIR,
            capture_output=True,
            text=True,
            timeout=5
        )

        if result.returncode != 0:
            return None

        remote_url = result.stdout.strip()

        # SSHå½¢å¼ (git@github.com:user/repo.git) ã¾ãŸã¯HTTPSå½¢å¼ã‚’è§£æ
        # SSHå½¢å¼ã®å ´åˆ
        ssh_match = re.match(r'git@github\.com:(.+)/(.+?)(?:\.git)?$', remote_url)
        if ssh_match:
            user, repo = ssh_match.groups()
        else:
            # HTTPSå½¢å¼ã®å ´åˆ
            https_match = re.match(r'https://github\.com/(.+)/(.+?)(?:\.git)?$', remote_url)
            if https_match:
                user, repo = https_match.groups()
            else:
                return None

        # ç¾åœ¨ã®ãƒ–ãƒ©ãƒ³ãƒåã‚’å–å¾—
        branch_result = subprocess.run(
            ["git", "rev-parse", "--abbrev-ref", "HEAD"],
            cwd=SCRIPT_DIR,
            capture_output=True,
            text=True,
            timeout=5
        )

        if branch_result.returncode != 0:
            branch = "main"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ–ãƒ©ãƒ³ãƒ
        else:
            branch = branch_result.stdout.strip()

        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        now = datetime.now()
        year = now.strftime("%Y")
        date_str = now.strftime("%Y%m%d")
        relative_path = f"reports/{year}/{date_str}.md"

        # GitHubä¸Šã®Markdownãƒ•ã‚¡ã‚¤ãƒ«URLã‚’ç”Ÿæˆ
        github_url = f"https://github.com/{user}/{repo}/blob/{branch}/{relative_path}"
        return github_url

    except Exception as e:
        print(f"Failed to generate GitHub URL: {e}")
        return None


def save_markdown_report(markdown_content):
    """Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹"""
    now = datetime.now()
    year = now.strftime("%Y")
    date_str = now.strftime("%Y%m%d")

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆï¼ˆreportsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã«ä¿å­˜ï¼‰
    report_dir = os.path.join(REPORTS_DIR, year)
    os.makedirs(report_dir, exist_ok=True)

    # Markdownãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    md_filepath = os.path.join(report_dir, f"{date_str}.md")
    with open(md_filepath, "w", encoding="utf-8") as f:
        f.write(markdown_content)

    print(f"Markdown report saved: {md_filepath}")

    # GitHubä¸Šã®Markdownãƒ•ã‚¡ã‚¤ãƒ«URLã‚’å–å¾—
    github_url = get_github_markdown_url()

    return md_filepath, github_url


def send_email_summary(paper_count, report_filepath, github_url=None):
    """è«–æ–‡æ•°ã¨GitHub URLã‚’å«ã‚€ç°¡æ½”ãªãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã™ã‚‹"""
    sender_email = os.getenv("GMAIL_SENDER")
    receiver_email = os.getenv("GMAIL_RECEIVER")
    app_password = os.getenv("GMAIL_APP_PASSWORD")

    if not all([sender_email, receiver_email, app_password]):
        print("\nError: Email environment variables (GMAIL_SENDER, GMAIL_RECEIVER, GMAIL_APP_PASSWORD) are not set.")
        print("Skipping email sending.")
        return

    print("\nSending email summary...")

    today_str = datetime.now().strftime("%Y-%m-%d")

    # ãƒ¡ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    msg = MIMEMultipart('alternative')
    msg['Subject'] = f"arXiv ãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ ({today_str})"
    msg['From'] = sender_email
    msg['To'] = receiver_email

    # ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‚’ä½œæˆ
    if github_url:
        email_body = f"""arXiv ãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ ({today_str})

æœ¬æ—¥ã®é–¢é€£è«–æ–‡æ•°: {paper_count}ä»¶

ãƒ¬ãƒãƒ¼ãƒˆé–²è¦§: {github_url}

ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {report_filepath}
"""
    else:
        email_body = f"""arXiv ãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ ({today_str})

æœ¬æ—¥ã®é–¢é€£è«–æ–‡æ•°: {paper_count}ä»¶

ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_filepath}
"""

    # ãƒ†ã‚­ã‚¹ãƒˆãƒ‘ãƒ¼ãƒˆã®ã‚¢ã‚¿ãƒƒãƒ
    part_text = MIMEText(email_body, 'plain', 'utf-8')
    msg.attach(part_text)

    # Gmailã®SMTPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¦é€ä¿¡
    try:
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(sender_email, app_password)
        server.send_message(msg)
        server.quit()
        print(f"Email sent successfully to {receiver_email}!")
    except Exception as e:
        print(f"Failed to send email: {e}")


def main():
    papers_to_process = fetch_and_filter_papers()

    processed_papers = []
    if papers_to_process:
        for i, paper in enumerate(papers_to_process):
            try:
                print(f"\n--- Processing paper {i+1}/{len(papers_to_process)}: {paper['title'][:50]}... ---")
                print("  - Evaluating authors...")
                paper["authors_evaluation"] = evaluate_authors_via_semantic_scholar(paper["authors"])
                print("    -> Author evaluation complete.")
                max_h_index = 0
                if paper["authors_evaluation"]:
                    max_h_index = max(author.get("hIndex", 0) for author in paper["authors_evaluation"])
                paper["preprint_score"] = max_h_index
                processed_papers.append(paper)
            except Exception as e:
                print(f"An error occurred while processing paper ID {paper['id']}: {e}")
                continue

    print("\nAll processing finished!")

    # Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    markdown_report = generate_markdown_report(processed_papers)

    # Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    report_filepath, github_url = save_markdown_report(markdown_report)

    # è«–æ–‡æ•°ã¨GitHub URLã‚’å«ã‚€ç°¡æ½”ãªãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡
    send_email_summary(len(processed_papers), report_filepath, github_url)


if __name__ == "__main__":
    main()
